"""„É°„Ç§„É≥„ÉØ„Éº„ÇØ„Éï„É≠„Éº„É¢„Ç∏„É•„Éº„É´ (Refactored with Strategy Pattern)

YouTubeÂãïÁîªËá™ÂãïÁîüÊàê„ÅÆÂÖ®Â∑•Á®ã„ÇíÁµ±Âêà„ÉªÂÆüË°å„Åó„Åæ„Åô„ÄÇ
WorkflowStep„Éë„Çø„Éº„É≥„Å´„Çà„Çä„ÄÅÂêÑ„Çπ„ÉÜ„ÉÉ„Éó„ÅåÁã¨Á´ã„Åó„Å¶„ÉÜ„Çπ„ÉàÂèØËÉΩ„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ
"""

import asyncio
import logging
import os
import re
import time
import traceback
from datetime import datetime
from typing import Any, Dict, List, Optional

from app.logging_config import get_log_session, setup_logging

# Áí∞Â¢ÉÂ§âÊï∞„Åã„Çâ„É≠„Ç∞„É¨„Éô„É´ÂèñÂæóÔºà„Éá„Éï„Ç©„É´„Éà„ÅØINFOÔºâ
log_level_str = os.getenv("LOG_LEVEL", "INFO")
log_level = getattr(logging, log_level_str.upper(), logging.INFO)

# „É≠„ÇÆ„É≥„Ç∞„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó
_LOG_SESSION = setup_logging(log_level=log_level)

from .api_rotation import initialize_api_infrastructure
from .config import cfg
from .discord import discord_notifier
from .metadata_storage import metadata_storage
from .models.workflow import WorkflowResult
from .sheets import sheets_manager
from .workflow import (
    AlignSubtitlesStep,
    CollectNewsStep,
    GenerateMetadataStep,
    GenerateScriptStep,
    GenerateThumbnailStep,
    GenerateVideoStep,
    GenerateVisualDesignStep,
    QualityAssuranceStep,
    ReviewVideoStep,
    SynthesizeAudioStep,
    TranscribeAudioStep,
    UploadToDriveStep,
    UploadToYouTubeStep,
    WorkflowContext,
    WorkflowStep,
)

logger = logging.getLogger(__name__)

# Initialize API infrastructure once at module import
initialize_api_infrastructure()
logger.info("API infrastructure initialized at startup")


class YouTubeWorkflow:
    """YouTubeÂãïÁîªËá™ÂãïÁîüÊàê„ÉØ„Éº„ÇØ„Éï„É≠„Éº (Strategy Pattern)

    ÂêÑ„Çπ„ÉÜ„ÉÉ„Éó„ÅØWorkflowStep„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÂÆüË£Ö„Åó„ÅüÁã¨Á´ã„Åó„Åü„ÇØ„É©„Çπ„Å®„Åó„Å¶ÂÆöÁæ©„Åï„Çå„ÄÅ
    „Åì„ÅÆ„ÇØ„É©„Çπ„ÅØ„Ç™„Éº„Ç±„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥„ÅÆ„Åø„ÇíÊãÖÂΩì„Åó„Åæ„Åô„ÄÇ
    """

    RETRY_CLEANUP_MAP = {
        "script_generation": {"script_content", "script_path"},
        "visual_design_generation": {"visual_design", "visual_design_dict"},
        "metadata_generation": {"metadata"},
        "thumbnail_generation": {"thumbnail_path"},
        "audio_synthesis": {"audio_path"},
        "audio_transcription": {"stt_words"},
        "subtitle_alignment": {"subtitle_path", "aligned_subtitles"},
        "video_generation": {
            "video_path",
            "archived_audio_path",
            "archived_subtitle_path",
            "broll_path",
            "broll_metadata",
            "broll_keywords",
            "broll_clip_paths",
            "broll_source",
            "use_stock_footage",
            "archived_broll_path",
        },
        "media_quality_assurance": {"qa_report", "qa_report_path", "qa_passed", "qa_retry_request"},
        "drive_upload": {"drive_result"},
        "youtube_upload": {"youtube_result", "video_id", "video_url"},
    }

    def __init__(self):
        self.run_id = None
        self.mode = "daily"
        self.context: Optional[WorkflowContext] = None
        self._log_session = get_log_session()

        # Define workflow steps (dependency injection ready)
        # NOTE: Ë¶ñË¶ö„Éá„Ç∂„Ç§„É≥ÁîüÊàê‚Üí„Çµ„É†„Éç„Ç§„É´/„É°„Çø„Éá„Éº„Çø‚ÜíÂãïÁîªÁîüÊàê„ÅÆÈ†ÜÂ∫è„ÅßË¶ñË¶öÁöÑÁµ±‰∏ÄÊÄß„ÇíÁ¢∫‰øù
        self.steps: List[WorkflowStep] = [
            CollectNewsStep(),  # Step 1: „Éã„É•„Éº„ÇπÂèéÈõÜ
            GenerateScriptStep(),  # Step 2: Âè∞Êú¨ÁîüÊàê
            GenerateVisualDesignStep(),  # Step 2.5: Áµ±‰∏Ä„Éì„Ç∏„É•„Ç¢„É´„Éá„Ç∂„Ç§„É≥ÁîüÊàê (NEW)
            GenerateMetadataStep(),  # Step 3: „É°„Çø„Éá„Éº„ÇøÁîüÊàê
            GenerateThumbnailStep(),  # Step 4: „Çµ„É†„Éç„Ç§„É´ÁîüÊàê
            SynthesizeAudioStep(),  # Step 5: Èü≥Â£∞ÂêàÊàê
            TranscribeAudioStep(),  # Step 6: Èü≥Â£∞Ë™çË≠ò
            AlignSubtitlesStep(),  # Step 7: Â≠óÂπïÊï¥Âêà
            GenerateVideoStep(),  # Step 8: ÂãïÁîªÁîüÊàê (Áµ±‰∏Ä„Éá„Ç∂„Ç§„É≥„Çí‰ΩøÁî®)
            QualityAssuranceStep(),  # Step 9: Ëá™ÂãïQA„Ç≤„Éº„Éà
            UploadToDriveStep(),  # Step 10: Drive „Ç¢„ÉÉ„Éó„É≠„Éº„Éâ
            UploadToYouTubeStep(),  # Step 11: YouTube „Ç¢„ÉÉ„Éó„É≠„Éº„Éâ
            ReviewVideoStep(),  # Step 12: AI„É¨„Éì„É•„Éº„ÅßÊîπÂñÑ„É≠„Ç∞ÁîüÊàê
        ]

    async def execute_full_workflow(self, mode: str = "daily") -> Dict[str, Any]:
        """ÂÆåÂÖ®„Å™„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÂÆüË°å

        Args:
            mode: ÂÆüË°å„É¢„Éº„Éâ (daily/special/test)

        Returns:
            ÂÆüË°åÁµêÊûú„ÅÆËæûÊõ∏
        """
        start_time = datetime.now()

        try:
            self.mode = mode
            self.run_id = self._initialize_run(mode)
            self.context = WorkflowContext(run_id=self.run_id, mode=mode)

            await self._notify_workflow_start(mode)

            qa_gating = getattr(getattr(cfg, "media_quality", None), "gating", None)
            max_attempts = 1 + max(0, getattr(qa_gating, "retry_attempts", 0))
            start_index = 0
            step_results: List[Optional[Any]] = [None] * len(self.steps)

            attempt = 0
            while attempt < max_attempts:
                attempt += 1
                logger.info(f"üöÄ Workflow attempt {attempt}/{max_attempts}")

                retry_triggered = False

                for index in range(start_index, len(self.steps)):
                    step = self.steps[index]
                    logger.info(f"Executing: {step.step_name}")
                    result = await step.execute(self.context)
                    step_results[index] = result

                    if result.files_generated:
                        self.context.add_files(result.files_generated)

                    if not result.success:
                        if isinstance(step, QualityAssuranceStep):
                            retry_request = self.context.get("qa_retry_request")
                            if retry_request and attempt < max_attempts:
                                retry_step_name = retry_request.get("start_step")
                                retry_index = self._resolve_step_index(retry_step_name)
                                if retry_index is None:
                                    logger.error(
                                        "QA retry requested an unknown step '%s'",
                                        retry_step_name,
                                    )
                                    return await self._handle_workflow_failure(step.step_name, result)

                                reason = retry_request.get("reason")
                                if reason:
                                    logger.warning(reason)

                                logger.warning(
                                    "Retrying workflow from step '%s' (attempt %s/%s)",
                                    self.steps[retry_index].step_name,
                                    attempt + 1,
                                    max_attempts,
                                )

                                self._prepare_context_for_retry(retry_index)
                                self._clear_step_results(step_results, retry_index)
                                start_index = retry_index
                                retry_triggered = True
                                break

                        logger.error(f"Step {step.step_name} failed on attempt {attempt}")
                        return await self._handle_workflow_failure(step.step_name, result)

                if retry_triggered:
                    continue

                final_results = [res for res in step_results if res is not None]

                video_url = self.context.get("video_url")
                if video_url:
                    metadata_storage.update_video_stats(run_id=self.run_id, video_url=video_url)
                    logger.info("Updated metadata storage with video URL")

                execution_time = (datetime.now() - start_time).total_seconds()
                result = self._compile_final_result(final_results, execution_time)

                if self._log_session:
                    self._log_session.mark_status(
                        "succeeded",
                        execution_time_seconds=execution_time,
                        attempts=attempt,
                        max_attempts=max_attempts,
                        steps=[step.step_name for step in self.steps],
                        video_url=video_url,
                        news_count=result.get("news_count"),
                    )

                await self._notify_workflow_success(result)
                self._update_run_status("completed", result)

                return result

            logger.error("Workflow failed after exhausting QA retries")
            failure_index = max(start_index, 0)
            failure_step = self.steps[failure_index].step_name if failure_index < len(self.steps) else "unknown"
            failure_result = step_results[failure_index] if failure_index < len(step_results) else None
            return await self._handle_workflow_failure(failure_step, failure_result)

        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            error_result = {
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc(),
                "execution_time": execution_time,
                "run_id": self.run_id,
            }
            await self._notify_workflow_error(e)
            self._update_run_status("failed", error_result)
            if self._log_session:
                self._log_session.mark_status(
                    "failed",
                    error=str(e),
                    step="exception",
                    execution_time_seconds=execution_time,
                )
            return error_result
        finally:
            self._cleanup_temp_files()

    def _resolve_step_index(self, step_name: Optional[str]) -> Optional[int]:
        """Given a step name, return its index within the workflow."""
        if not step_name:
            return None
        for idx, step in enumerate(self.steps):
            if step.step_name == step_name:
                return idx
        return None

    def _prepare_context_for_retry(self, start_index: int) -> None:
        """Remove context state produced by steps at or after start_index."""
        if not self.context:
            return

        keys_to_remove = set()
        for step in self.steps[start_index:]:
            keys_to_remove.update(self.RETRY_CLEANUP_MAP.get(step.step_name, set()))

        for key in keys_to_remove:
            if key in self.context.state:
                self.context.state.pop(key, None)

    def _clear_step_results(self, step_results: List[Optional[Any]], start_index: int) -> None:
        """Clear cached StepResult objects for retry region."""
        for idx in range(start_index, len(step_results)):
            step_results[idx] = None

    def _initialize_run(self, mode: str) -> str:
        """„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂÆüË°åID„ÇíÂàùÊúüÂåñ"""
        if sheets_manager:
            run_id = sheets_manager.create_run(mode)
            logger.info(f"Initialized workflow run: {run_id}")
            if self._log_session:
                self._log_session.bind_workflow_run(run_id, mode=mode)
            return run_id

        run_id = f"local_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        logger.warning(f"Sheets not available, using local run ID: {run_id}")
        if self._log_session:
            self._log_session.bind_workflow_run(run_id, mode=mode)
        return run_id

    async def _handle_workflow_failure(self, step_name: str, result: Any) -> Dict[str, Any]:
        """„Çπ„ÉÜ„ÉÉ„ÉóÂ§±ÊïóÊôÇ„ÅÆÂá¶ÁêÜ"""
        error_message = f"{step_name} failed: {result.error if hasattr(result, 'error') else 'Unknown error'}"
        logger.error(error_message)
        await self._notify_workflow_error(RuntimeError(error_message))
        self._update_run_status("failed", {"error": error_message})
        if self._log_session:
            self._log_session.mark_status(
                "failed",
                failed_step=step_name,
                error=error_message,
                run_id=self.run_id,
            )
        return {
            "success": False,
            "failed_step": step_name,
            "error": result.error if hasattr(result, "error") else str(result),
            "run_id": self.run_id,
        }

    def _compile_final_result(self, step_results: List[Any], execution_time: float) -> Dict[str, Any]:
        """ÊúÄÁµÇÁµêÊûú„ÇíÈõÜÁ¥Ñ„Åó„Å¶WorkflowResult„ÇíÁîüÊàê"""

        # Extract key data from steps
        news_count = step_results[0].get("count", 0) if step_results else 0
        script_length = step_results[1].get("length", 0) if len(step_results) > 1 else 0

        video_path = self.context.get("video_path")
        video_id = self.context.get("video_id")
        video_url = self.context.get("video_url")
        thumbnail_path = self.context.get("thumbnail_path")

        metadata = self.context.get("metadata", {})
        title = metadata.get("title") if metadata else None

        video_review_data = self.context.get("video_review") if self.context else None
        video_review_summary = None
        video_review_actions: List[str] = []
        if isinstance(video_review_data, dict):
            feedback_block = video_review_data.get("feedback") or {}
            if isinstance(feedback_block, dict):
                video_review_summary = feedback_block.get("summary")
                actions = feedback_block.get("next_video_actions") or []
                if isinstance(actions, list):
                    video_review_actions = [str(action) for action in actions if action]
                elif actions:
                    video_review_actions = [str(actions)]

        # Create WorkflowResult with rich data
        script_step = step_results[1] if len(step_results) > 1 else None

        workflow_result = WorkflowResult(
            success=True,
            run_id=self.run_id,
            mode=self.mode,
            execution_time_seconds=execution_time,
            news_count=news_count,
            script_length=script_length,
            video_path=video_path,
            video_id=video_id,
            video_url=video_url,
            title=title,
            thumbnail_path=thumbnail_path,
            # Quality metrics (extract if available)
            wow_score=self._extract_wow_score(script_step),
            surprise_points=self._extract_surprise_points(script_step),
            emotion_peaks=self._extract_emotion_peaks(script_step),
            visual_instructions=self._extract_visual_instructions(script_step),
            retention_prediction=self._extract_retention_prediction(script_step),
            japanese_purity=self._extract_japanese_purity(script_step),
            # Hook classification
            hook_type=self._classify_hook_from_script(script_step),
            topic=self._extract_topic(step_results[0] if step_results else None),
            completed_steps=sum(1 for s in step_results if s.success),
            failed_steps=sum(1 for s in step_results if not s.success),
            total_steps=len(self.steps),
            generated_files=self.context.generated_files if self.context else [],
            video_review_summary=video_review_summary,
            video_review_actions=video_review_actions,
        )

        # Log to feedback system
        metadata_storage.log_execution(workflow_result)

        # Return dict for backward compatibility
        result = {
            "success": True,
            "run_id": self.run_id,
            "execution_time": execution_time,
            "generated_files": self.context.generated_files if self.context else [],
            "steps": {},
        }

        step_names = [step.step_name for step in self.steps]
        for i, step_result in enumerate(step_results):
            if i < len(step_names):
                result["steps"][step_names[i]] = {"success": step_result.success, **step_result.data}

        result["news_count"] = news_count
        result["script_length"] = script_length
        result["video_path"] = video_path
        result["video_id"] = video_id
        result["video_url"] = video_url
        result["drive_folder"] = self.context.get("folder_id") if self.context else None
        result["video_review"] = video_review_data

        return result

    def _extract_wow_score(self, script_step: Any) -> Optional[float]:
        """Extract WOW score from script generation step."""
        if not script_step or not hasattr(script_step, "data"):
            return None

        metrics = script_step.data.get("script_metrics", {})
        if not metrics:
            return None

        # Try to extract from quality_guarantee structure
        return metrics.get("wow_score")

    def _extract_japanese_purity(self, script_step: Any) -> Optional[float]:
        """Extract Japanese purity from script generation step."""
        if not script_step or not hasattr(script_step, "data"):
            return None

        # First try direct field
        purity = script_step.data.get("japanese_purity_score")
        if purity:
            return purity

        # Then try from quality_data
        metrics = script_step.data.get("script_metrics", {})
        return metrics.get("japanese_purity")

    def _extract_surprise_points(self, script_step: Any) -> Optional[int]:
        """Extract surprise points count from quality data."""
        if not script_step or not hasattr(script_step, "data"):
            return None

        metrics = script_step.data.get("script_metrics", {})
        return metrics.get("surprise_points")

    def _extract_emotion_peaks(self, script_step: Any) -> Optional[int]:
        """Extract emotion peaks count from quality data."""
        if not script_step or not hasattr(script_step, "data"):
            return None

        metrics = script_step.data.get("script_metrics", {})
        return metrics.get("emotion_peaks")

    def _extract_visual_instructions(self, script_step: Any) -> Optional[int]:
        """Extract visual instructions count from quality data."""
        if not script_step or not hasattr(script_step, "data"):
            return None

        metrics = script_step.data.get("script_metrics", {})
        return metrics.get("visual_instructions")

    def _extract_retention_prediction(self, script_step: Any) -> Optional[float]:
        """Extract retention prediction from quality data."""
        if not script_step or not hasattr(script_step, "data"):
            return None

        metrics = script_step.data.get("script_metrics", {})
        return metrics.get("retention_prediction")

    def _classify_hook_from_script(self, script_step: Any) -> str:
        """Classify hook strategy from script content."""
        if not script_step or not hasattr(script_step, "data"):
            return "„Åù„ÅÆ‰ªñ"

        script_content = script_step.data.get("script", "")
        if not script_content:
            return "„Åù„ÅÆ‰ªñ"

        # Get first 200 chars
        first_segment = script_content[:200]

        if re.search(r"(È©ö„Åç|Ë°ùÊíÉ|„Åæ„Åï„Åã|‰ø°„Åò„Çâ„Çå„Å™„ÅÑ)", first_segment):
            return "Ë°ùÊíÉÁöÑ‰∫ãÂÆü"
        elif re.search(r"(„Å™„Åú|„Å©„ÅÜ„Åó„Å¶|ÁêÜÁî±|ÂéüÂõ†)", first_segment):
            return "ÁñëÂïèÊèêËµ∑"
        elif re.search(r"\d+[%ÔºÖ]|\d+ÂÑÑ|\d+ÂÄç", first_segment):
            return "ÊÑèÂ§ñ„Å™Êï∞Â≠ó"
        elif re.search(r"(Áü•„Çâ„Å™„ÅÑ|Èö†„Åï„Çå„Åü|Ë£èÂÅ¥|ÁúüÂÆü)", first_segment):
            return "Èö†„Åï„Çå„ÅüÁúüÂÆü"
        return "„Åù„ÅÆ‰ªñ"

    def _extract_topic(self, news_step: Any) -> str:
        """Extract main topic from news items."""
        if not news_step or not hasattr(news_step, "data"):
            return "‰∏ÄËà¨"

        news_items = news_step.data.get("news_items", [])
        if not news_items:
            return "‰∏ÄËà¨"

        # Simple extraction from first news title
        first_title = news_items[0].get("title", "") if news_items else ""
        if "Ê†™" in first_title or "Êó•Áµå" in first_title:
            return "Ê†™ÂºèÂ∏ÇÂ†¥"
        elif "ÈáëÂà©" in first_title or "Âà©‰∏ä„Åí" in first_title or "Êó•ÈäÄ" in first_title:
            return "ÈáëËûçÊîøÁ≠ñ"
        elif "ÂÜÜÂÆâ" in first_title or "ÂÜÜÈ´ò" in first_title or "ÁÇ∫Êõø" in first_title:
            return "ÁÇ∫Êõø"
        elif "GDP" in first_title or "ÊôØÊ∞ó" in first_title:
            return "ÁµåÊ∏àÊåáÊ®ô"
        return "‰∏ÄËà¨"

    async def _notify_workflow_start(self, mode: str):
        """„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÈñãÂßãÈÄöÁü•"""
        message = f"YouTubeÂãïÁîªÁîüÊàê„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü\n„É¢„Éº„Éâ: {mode}\nRun ID: {self.run_id}"
        discord_notifier.notify(message, level="info", title="„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÈñãÂßã")

    async def _notify_workflow_success(self, result: Dict[str, Any]):
        """„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÊàêÂäüÈÄöÁü•"""
        execution_time = result.get("execution_time", 0)
        video_url = result.get("video_url", "N/A")
        message = f"YouTubeÂãïÁîªÁîüÊàê„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ\nÂÆüË°åÊôÇÈñì: {execution_time:.1f}Áßí\nÂãïÁîªURL: {video_url}"
        fields = {
            "„Éã„É•„Éº„Çπ‰ª∂Êï∞": result.get("news_count", 0),
            "Âè∞Êú¨ÊñáÂ≠óÊï∞": result.get("script_length", 0),
            "ÁîüÊàê„Éï„Ç°„Ç§„É´Êï∞": len(result.get("generated_files", [])),
        }
        discord_notifier.notify(message, level="success", title="„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂÆå‰∫Ü", fields=fields)

    async def _notify_workflow_error(self, error: Exception):
        """„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Ç®„É©„ÉºÈÄöÁü•"""
        message = f"YouTubeÂãïÁîªÁîüÊàê„Åß„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü\n„Ç®„É©„Éº: {str(error)}\nRun ID: {self.run_id}"
        discord_notifier.notify(message, level="error", title="„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Ç®„É©„Éº")

    def _update_run_status(self, status: str, result: Dict[str, Any]):
        """ÂÆüË°å„Çπ„ÉÜ„Éº„Çø„Çπ„ÇíÊõ¥Êñ∞"""
        try:
            if sheets_manager and self.run_id:
                sheets_manager.update_run(self.run_id, status=status, error_log=str(result))
        except Exception as e:
            logger.warning(f"Failed to update run status: {e}")

    def _cleanup_temp_files(self):
        """‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„Çí„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó"""
        if not self.context:
            return

        cleaned_count = 0
        for file_path in self.context.generated_files:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    cleaned_count += 1
            except Exception as e:
                logger.warning(f"Failed to cleanup file {file_path}: {e}")

        if cleaned_count > 0:
            logger.info(f"Cleaned up {cleaned_count} temporary files")


# Backward compatibility: expose workflow via container
def _get_workflow() -> YouTubeWorkflow:
    """Get workflow instance from container (backward compatibility)."""
    from .container import get_container

    return get_container().workflow


# Legacy global variable (backward compatibility)
# Deprecated: Use _get_workflow() or container.workflow instead
class _WorkflowProxy:
    """Proxy object to maintain backward compatibility with 'workflow' global."""

    def __getattr__(self, name):
        return getattr(_get_workflow(), name)


workflow = _WorkflowProxy()


async def run_daily_workflow() -> Dict[str, Any]:
    """Êó•Ê¨°„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂÆüË°å"""
    return await _get_workflow().execute_full_workflow("daily")


async def run_special_workflow() -> Dict[str, Any]:
    """ÁâπÂà•„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂÆüË°å"""
    return await _get_workflow().execute_full_workflow("special")


async def run_test_workflow() -> Dict[str, Any]:
    """„ÉÜ„Çπ„Éà„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂÆüË°å"""
    return await _get_workflow().execute_full_workflow("test")


if __name__ == "__main__":
    import sys

    async def main():
        mode = sys.argv[1] if len(sys.argv) > 1 else "test"
        logger.info(f"üöÄ Starting YouTube Workflow ({mode} mode)")

        try:
            start_time = time.time()
            result = await _get_workflow().execute_full_workflow(mode)
            duration = time.time() - start_time

            if result.get("success"):
                logger.info(f"‚úÖ Workflow completed successfully! (Execution time: {duration:.1f}s)")
                logger.info(f"Video URL: {result.get('video_url', 'N/A')}")
                logger.info(f"Files generated: {len(result.get('generated_files', []))}")
            else:
                logger.error(f"‚ùå Workflow failed: {result.get('error', 'Unknown error')}")
                sys.exit(1)
        except KeyboardInterrupt:
            logger.warning("‚ö†Ô∏è Workflow interrupted by user")
            sys.exit(130)
        except Exception as e:
            logger.error(f"‚ùå Unexpected error: {e}", exc_info=True)
            sys.exit(1)

    asyncio.run(main())
