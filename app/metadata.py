""" ""
ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

YouTubeå‹•ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«ã€èª¬æ˜æ–‡ã€ã‚¿ã‚°ã€ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚
SEOæœ€é©åŒ–ã¨è¦–è´è€…ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‘ä¸Šã‚’ç›®çš„ã¨ã—ãŸé«˜å“è³ªãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™ã€‚
"""

import json
import logging
import re
from datetime import datetime
from typing import Any, Dict, List

import google.generativeai as genai

from .api_rotation import get_rotation_manager  # è¿½åŠ 
from .config import cfg
from .llm_logging import llm_logging_context, record_llm_interaction
from app.constants.prompts import (
    DEFAULT_VIDEO_MODE_CONTEXT,
    METADATA_MODE_CONTEXT,
    METADATA_OTHER_POLICIES_LINES,
    METADATA_REQUIREMENTS_LINES,
    METADATA_TITLE_AVOID_EXAMPLES,
    METADATA_TITLE_POLICY_LINES,
    METADATA_TITLE_SUCCESS_EXAMPLES,
    indent_lines,
    join_lines,
)

logger = logging.getLogger(__name__)


class MetadataGenerator:
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.client = None
        self._setup_client()

    def _setup_client(self):
        """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–

        Note: ã‚­ãƒ¼ç™»éŒ²ã¯ main.py ã® initialize_api_infrastructure() ã§å®Ÿè¡Œæ¸ˆã¿
        """
        try:
            # Rotation managerã¯æ—¢ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æ
            self.client = None
            logger.info("Metadata generator ready (using shared rotation manager)")

        except Exception as e:
            logger.error(f"Failed to initialize metadata generator: {e}")
            raise

    def generate_youtube_metadata(
        self, news_items: List[Dict[str, Any]], script_content: str = "", mode: str = "daily"
    ) -> Dict[str, Any]:
        """YouTubeå‹•ç”»ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        try:
            with llm_logging_context(component="metadata_generation", mode=mode):
                prompt = self._build_metadata_prompt(news_items, script_content, mode)
                response = self._call_gemini_for_metadata(prompt)
                metadata = self._parse_metadata_response(response)
                validated_metadata = self._validate_metadata(metadata, news_items)
                logger.info(f"Generated metadata for {mode} video")
                return validated_metadata
        except Exception as e:
            logger.error(f"Failed to generate metadata: {e}")
            return self._get_fallback_metadata(news_items, mode)

    def _build_metadata_prompt(self, news_items: List[Dict[str, Any]], script_content: str, mode: str) -> str:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        news_summary = self._create_news_summary(news_items)
        mode_description = METADATA_MODE_CONTEXT.get(mode, DEFAULT_VIDEO_MODE_CONTEXT)
        requirements = join_lines(METADATA_REQUIREMENTS_LINES)
        title_policy = join_lines(METADATA_TITLE_POLICY_LINES)
        success_examples = indent_lines(METADATA_TITLE_SUCCESS_EXAMPLES, prefix="  - ")
        avoid_examples = indent_lines(METADATA_TITLE_AVOID_EXAMPLES, prefix="  - ")
        other_policies = join_lines(METADATA_OTHER_POLICIES_LINES)
        prompt = f"""
ä»¥ä¸‹ã®çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã‹ã‚‰ã€YouTubeå‹•ç”»ç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€å‹•ç”»ã‚¿ã‚¤ãƒ—ã€‘{mode_description}
ã€é…ä¿¡æ—¥ã€‘{current_date}

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã€‘
{news_summary}

ã€å°æœ¬æŠœç²‹ã€‘
{script_content[:500] if script_content else "å°æœ¬ãƒ‡ãƒ¼ã‚¿ãªã—"}...

ã€è¦ä»¶ã€‘
{requirements}

ã€ã‚¿ã‚¤ãƒˆãƒ«ä½œæˆã®é‡è¦æ–¹é‡ã€‘
{title_policy}

âœ… **æˆåŠŸä¾‹:**
{success_examples}

âŒ **é¿ã‘ã‚‹ã¹ãä¾‹:**
{avoid_examples}

ã€ãã®ä»–ã®æ–¹é‡ã€‘
{other_policies}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å³å¯†ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
  "title": "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",
  "description": "å‹•ç”»èª¬æ˜æ–‡ï¼ˆæ”¹è¡Œã‚’\\nã§è¡¨ç¾ï¼‰",
  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", "ã‚¿ã‚°3", ...],
  "category": "YouTube ã‚«ãƒ†ã‚´ãƒª",
  "thumbnail_text": "ã‚µãƒ ãƒã‚¤ãƒ«ç”¨ãƒ†ã‚­ã‚¹ãƒˆ",
  "seo_keywords": ["SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...],
  "target_audience": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¦–è´è€…å±¤",
  "estimated_watch_time": "æ¨å®šè¦–è´æ™‚é–“ï¼ˆåˆ†ï¼‰"
}}
```

æ³¨æ„äº‹é …ï¼š
- å¿…ãšæœ‰åŠ¹ãªJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”
- ã‚¿ã‚¤ãƒˆãƒ«ã¯é­…åŠ›çš„ã ãŒèª‡å¼µã—ãªã„
- èª¬æ˜æ–‡ã«ã¯å‡ºå…¸æƒ…å ±ã‚’å«ã‚ã‚‹
- ã‚¿ã‚°ã¯å…·ä½“çš„ã§æ¤œç´¢æ€§ã®é«˜ã„ã‚‚ã®ã‚’é¸æŠ
"""
        return prompt

    def _create_news_summary(self, news_items: List[Dict[str, Any]]) -> str:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã‹ã‚‰è¦ç´„ã‚’ä½œæˆ"""
        if not news_items:
            return "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        summaries = []
        for i, item in enumerate(news_items, 1):
            summary = f"""
ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹{i}ã€‘{item.get("title", "ç„¡é¡Œ")}
å‡ºå…¸: {item.get("source", "ä¸æ˜")}
è¦ç´„: {item.get("summary", "")[:200]}...
å½±éŸ¿åº¦: {item.get("impact_level", "medium")}
"""
            summaries.append(summary)
        return "\n".join(summaries)

    def _call_gemini_for_metadata(self, prompt: str, max_retries: int = 3) -> str:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆç”¨Gemini APIå‘¼ã³å‡ºã—ï¼ˆã‚­ãƒ¼ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
        rotation_manager = get_rotation_manager()

        def api_call_with_key(api_key: str) -> str:
            """å˜ä¸€APIã‚­ãƒ¼ã§ã®å‘¼ã³å‡ºã—"""
            try:
                genai.configure(api_key=api_key)
                model_name = cfg.gemini_models.get("metadata_generation")
                client = genai.GenerativeModel(f"models/{model_name}")

                generation_config = genai.GenerationConfig(
                    temperature=0.7,
                    top_p=0.95,
                    top_k=40,
                    max_output_tokens=4096,
                )

                response = client.generate_content(prompt, generation_config=generation_config)
                content = response.text
                logger.debug(f"Generated metadata response length: {len(content)}")

                try:
                    record_llm_interaction(
                        provider="gemini",
                        model=f"models/{model_name}",
                        prompt={
                            "text": prompt,
                            "generation_config": {
                                "temperature": getattr(generation_config, "temperature", None),
                                "top_p": getattr(generation_config, "top_p", None),
                                "top_k": getattr(generation_config, "top_k", None),
                                "max_output_tokens": getattr(generation_config, "max_output_tokens", None),
                            },
                        },
                        response={
                            "text": content,
                        },
                        metadata={"component": "metadata_generation"},
                    )
                except Exception:  # pragma: no cover - logging should never interrupt flow
                    logger.debug("Failed to log metadata generation interaction", exc_info=True)

                return content

            except Exception as e:
                error_str = str(e).lower()
                if any(kw in error_str for kw in ["429", "rate limit", "quota"]):
                    logger.warning(f"Gemini rate limit detected: {e}")
                    raise
                if any(kw in error_str for kw in ["504", "deadline exceeded", "timeout"]):
                    logger.warning(f"Gemini timeout detected: {e}")
                    raise
                logger.warning(f"Gemini API error: {e}")
                raise

        try:
            return rotation_manager.execute_with_rotation(
                provider="gemini", api_call=api_call_with_key, max_attempts=max_retries
            )
        except Exception as e:
            logger.error(f"All Gemini API attempts failed for metadata generation: {e}")
            raise Exception("Gemini API failed with all keys for metadata generation")

    def _parse_metadata_response(self, response: str) -> Dict[str, Any]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ"""
        try:
            match = re.search(r"```json\n(.*?)\n```", response, re.DOTALL)
            if match:
                json_str = match.group(1)
            else:
                start = response.find("{")
                end = response.rfind("}")
                if start != -1 and end != -1:
                    json_str = response[start : end + 1]
                else:
                    raise ValueError("No JSON structure found")
            metadata = json.loads(json_str)
            return metadata
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse metadata JSON: {e}")
            logger.debug(f"Raw response: {response[:500]}...")
            return {}
        except Exception as e:
            logger.error(f"Error parsing metadata response: {e}")
            return {}

    def _validate_metadata(self, metadata: Dict[str, Any], news_items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        validated = {}
        try:
            title = str(metadata.get("title", "")).strip()
            if len(title) > 50:
                title = title[:47] + "..."
            validated["title"] = title or self._generate_fallback_title(news_items)
            description = str(metadata.get("description", "")).strip()
            description = description.replace("\\n", "\n")
            if len(description) < 100:
                description = self._enhance_description(description, news_items)
            validated["description"] = description
            tags = metadata.get("tags", [])
            if isinstance(tags, list):
                cleaned_tags = []
                for tag in tags[:20]:
                    clean_tag = str(tag).strip()
                    if clean_tag and len(clean_tag) <= 50:
                        cleaned_tags.append(clean_tag)
                validated["tags"] = cleaned_tags
            else:
                validated["tags"] = self._generate_fallback_tags(news_items)
            validated["category"] = str(metadata.get("category", "News & Politics"))
            validated["thumbnail_text"] = str(metadata.get("thumbnail_text", "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹"))
            validated["seo_keywords"] = metadata.get("seo_keywords", [])
            validated["target_audience"] = str(metadata.get("target_audience", "çµŒæ¸ˆã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…"))
            validated["estimated_watch_time"] = str(metadata.get("estimated_watch_time", "15-30åˆ†"))
            validated["generated_at"] = datetime.now().isoformat()
            validated["news_count"] = len(news_items)
            return validated
        except Exception as e:
            logger.error(f"Metadata validation error: {e}")
            return self._get_fallback_metadata(news_items, "daily")

    def _generate_fallback_title(self, news_items: List[Dict[str, Any]]) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆWOWè¦ç´ è¿½åŠ ï¼‰"""
        current_date = datetime.now().strftime("%m/%d")
        if news_items and len(news_items) > 0:
            main_topic = news_items[0].get("title", "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹")

            # WOWè¦ç´ ã‚’å«ã‚€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            wow_keywords = self._extract_wow_elements(main_topic)
            keywords = self._extract_keywords(main_topic)

            if wow_keywords:
                # WOWè¦ç´ ãŒã‚ã‚‹å ´åˆ
                return f"ã€é€Ÿå ±ã€‘{wow_keywords[0]}ï¼æ³¨ç›®ã®{keywords[0] if keywords else 'çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹'}"
            elif keywords:
                # é€šå¸¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã®å ´åˆã‚‚å¼·èª¿
                return f"ã€{current_date}ã€‘{keywords[0]}ãŒå‹•ãï¼ä»Šæ—¥ã®é‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹"

        return f"ã€{current_date}é€Ÿå ±ã€‘ä»Šæ—¥ã®çµŒæ¸ˆå¸‚å ´ã§ä½•ãŒèµ·ããŸï¼Ÿ"

    def _extract_wow_elements(self, text: str) -> List[str]:
        """WOWè¦ç´ ï¼ˆæ•°å­—ã€ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã€å¤‰å‹•è¡¨ç¾ï¼‰ã‚’æŠ½å‡º"""
        wow_elements = []

        # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸æŠ½å‡º
        percent_match = re.search(r"([+\-]?\d+\.?\d*[%ï¼…])", text)
        if percent_match:
            wow_elements.append(f"{percent_match.group(1)}å¤‰å‹•")

        # å€ç‡æŠ½å‡º
        bai_match = re.search(r"(\d+\.?\d*å€)", text)
        if bai_match:
            wow_elements.append(bai_match.group(1))

        # å¤‰å‹•è¡¨ç¾
        trend_patterns = [
            "æ€¥é¨°",
            "æš´è½",
            "æ€¥è½",
            "é«˜é¨°",
            "æ€¥ä¸Šæ˜‡",
            "æ€¥é™ä¸‹",
            "å²ä¸Šæœ€é«˜",
            "æœ€å®‰å€¤",
            "å¹´åˆæ¥é«˜å€¤",
            "å¹´åˆæ¥å®‰å€¤",
        ]
        for pattern in trend_patterns:
            if pattern in text:
                wow_elements.append(pattern)
                break

        # ç·Šæ€¥æ€§è¡¨ç¾
        urgent_patterns = ["é€Ÿå ±", "ç·Šæ€¥", "è¡æ’ƒ", "è­¦å‘Š", "æ³¨ç›®", "é‡å¤§"]
        for pattern in urgent_patterns:
            if pattern in text:
                wow_elements.append(pattern)
                break

        return wow_elements[:2]  # æœ€å¤§2ã¤

    def _enhance_description(self, description: str, news_items: List[Dict[str, Any]]) -> str:
        """èª¬æ˜æ–‡ã‚’æ‹¡å……"""
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        enhanced = f"{description}\n\n" if description else ""
        enhanced += f"""
ã€{current_date} çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€‘

æœ¬æ—¥ã®é‡è¦ãªçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å°‚é–€å®¶ãŒåˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¾ã™ã€‚

ğŸ“ˆ ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ï¼š
"""
        for i, item in enumerate(news_items, 1):
            enhanced += f"{i}. {item.get('title', 'ç„¡é¡Œ')}\n"
        enhanced += """

ğŸ¯ ã“ã®å‹•ç”»ã§å­¦ã¹ã‚‹ã“ã¨ï¼š
â€¢ æœ€æ–°ã®çµŒæ¸ˆå‹•å‘ã¨å¸‚å ´ã¸ã®å½±éŸ¿
â€¢ å°‚é–€å®¶ã«ã‚ˆã‚‹è©³ç´°åˆ†æã¨è§£èª¬
â€¢ ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆã¨æŠ•è³‡åˆ¤æ–­ææ–™

ğŸ“Š ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºï¼š
"""
        sources = set()
        for item in news_items:
            source = item.get("source")
            if source and source != "ã‚·ã‚¹ãƒ†ãƒ ":
                sources.add(source)
        for source in list(sources)[:5]:
            enhanced += f"â€¢ {source}\n"
        enhanced += """

âš ï¸ å…è²¬äº‹é …ï¼š
æœ¬å‹•ç”»ã®å†…å®¹ã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡å‹§èª˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚

#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #æ ªå¼å¸‚å ´ #é‡‘è #çµŒæ¸ˆè§£èª¬
"""
        return enhanced

    def _generate_fallback_tags(self, news_items: List[Dict[str, Any]]) -> List[str]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚¿ã‚°ç”Ÿæˆ"""
        base_tags = ["çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "æŠ•è³‡", "æ ªå¼å¸‚å ´", "é‡‘è", "çµŒæ¸ˆè§£èª¬", "ãƒãƒ¼ã‚±ãƒƒãƒˆ", "çµŒæ¸ˆåˆ†æ", "ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬"]
        for item in news_items:
            title = item.get("title", "")
            keywords = self._extract_keywords(title)
            base_tags.extend(keywords[:3])
        unique_tags = []
        for tag in base_tags:
            if tag not in unique_tags and len(tag) <= 50:
                unique_tags.append(tag)
        return unique_tags[:15]

    def _extract_keywords(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        economic_patterns = [
            r"æ—¥çµŒå¹³å‡",
            r"TOPIX",
            r"ãƒ€ã‚¦",
            r"ãƒŠã‚¹ãƒ€ãƒƒã‚¯",
            r"é‡‘åˆ©",
            r"ã‚¤ãƒ³ãƒ•ãƒ¬",
            r"GDP",
            r"å¤±æ¥­ç‡",
            r"ä¸­å¤®éŠ€è¡Œ",
            r"æ—¥éŠ€",
            r"FRB",
            r"ECB",
            r"æ ªä¾¡",
            r"ç‚ºæ›¿",
            r"å††å®‰",
            r"å††é«˜",
            r"ä¼æ¥­æ±ºç®—",
            r"æ¥­ç¸¾",
            r"å£²ä¸Š",
            r"åˆ©ç›Š",
            r"æ–°è¦ä¸Šå ´",
            r"IPO",
            r"M&A",
            r"è²·å",
        ]
        keywords = []
        for pattern in economic_patterns:
            if re.search(pattern, text):
                keywords.append(pattern.replace(r"\b", "").replace(r"\\", ""))
        return keywords[:5]

    def _get_fallback_metadata(self, news_items: List[Dict[str, Any]], mode: str) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆWOWè¦ç´ è¿½åŠ ï¼‰"""
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

        # WOWè¦ç´ ã‚’å«ã‚€ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
        fallback_title = self._generate_fallback_title(news_items)

        return {
            "title": fallback_title,
            "description": f"""
ã€{current_date} çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€‘

æœ¬æ—¥ã®é‡è¦ãªçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å°‚é–€å®¶ãŒåˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¾ã™ã€‚

ğŸ“ˆ ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ï¼š
"""
            + "\n".join([f"â€¢ {item.get('title', 'ç„¡é¡Œ')}" for item in news_items[:3]])
            + """

ğŸ¯ ã“ã®å‹•ç”»ã§å­¦ã¹ã‚‹ã“ã¨ï¼š
â€¢ æœ€æ–°ã®çµŒæ¸ˆå‹•å‘ã¨å¸‚å ´ã¸ã®å½±éŸ¿
â€¢ å°‚é–€å®¶ã«ã‚ˆã‚‹è©³ç´°åˆ†æã¨è§£èª¬
â€¢ ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ

âš ï¸ å…è²¬äº‹é …ï¼š
æœ¬å‹•ç”»ã®å†…å®¹ã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡å‹§èª˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #æ ªå¼å¸‚å ´ #é‡‘è #çµŒæ¸ˆè§£èª¬""",
            "tags": self._generate_fallback_tags(news_items),
            "category": "News & Politics",
            "thumbnail_text": "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬",
            "seo_keywords": ["çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "æŠ•è³‡", "æ ªå¼å¸‚å ´", "é‡‘è"],
            "target_audience": "çµŒæ¸ˆã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…",
            "estimated_watch_time": "15-30åˆ†",
            "generated_at": datetime.now().isoformat(),
            "news_count": len(news_items),
            "fallback": True,
        }

    def create_short_form_metadata(self, topic: str, duration_minutes: int = 1) -> Dict[str, Any]:
        """ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€YouTube Shortsç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

ãƒˆãƒ”ãƒƒã‚¯: {topic}
å‹•ç”»é•·: {duration_minutes}åˆ†

è¦ä»¶ï¼š
- ã‚¿ã‚¤ãƒˆãƒ«: 30æ–‡å­—ä»¥å†…ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆé‡è¦–
- èª¬æ˜æ–‡: 500æ–‡å­—ä»¥å†…ã€ç°¡æ½”ã§èˆˆå‘³ã‚’å¼•ã
- ã‚¿ã‚°: ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å‘ã‘ã€10å€‹ç¨‹åº¦
- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: ãƒˆãƒ¬ãƒ³ãƒ‰æ€§é‡è¦–

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "title": "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«",
  "description": "ç°¡æ½”ãªèª¬æ˜æ–‡",
  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", ...],
  "hashtags": ["#ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°1", "#ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°2", ...],
  "category": "News & Politics"
}}
"""
        try:
            response = self._call_gemini_for_metadata(prompt)
            metadata = self._parse_metadata_response(response)
            if metadata:
                metadata["video_type"] = "shorts"
                metadata["estimated_watch_time"] = f"{duration_minutes}åˆ†"
                metadata["generated_at"] = datetime.now().isoformat()
            return metadata or self._get_fallback_shorts_metadata(topic)
        except Exception as e:
            logger.error(f"Failed to generate shorts metadata: {e}")
            return self._get_fallback_shorts_metadata(topic)

    def _get_fallback_shorts_metadata(self, topic: str) -> Dict[str, Any]:
        """ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
        return {
            "title": f"ã€é€Ÿå ±ã€‘{topic}",
            "description": f"{topic}ã«ã¤ã„ã¦1åˆ†ã§è§£èª¬\n\n#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»",
            "tags": ["çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "æŠ•è³‡", "ã‚·ãƒ§ãƒ¼ãƒˆ", "é€Ÿå ±", topic],
            "hashtags": ["#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "#æŠ•è³‡", "#ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»", "#é€Ÿå ±"],
            "category": "News & Politics",
            "video_type": "shorts",
            "estimated_watch_time": "1åˆ†",
            "generated_at": datetime.now().isoformat(),
            "fallback": True,
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
metadata_generator = MetadataGenerator() if cfg.gemini_api_key else None


def generate_youtube_metadata(
    news_items: List[Dict[str, Any]], script_content: str = "", mode: str = "daily"
) -> Dict[str, Any]:
    """YouTube ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ç°¡æ˜“é–¢æ•°"""
    if metadata_generator:
        return metadata_generator.generate_youtube_metadata(news_items, script_content, mode)
    else:
        logger.warning("Metadata generator not available, using fallback")
        return MetadataGenerator()._get_fallback_metadata(news_items, mode)


def create_shorts_metadata(topic: str, duration_minutes: int = 1) -> Dict[str, Any]:
    """ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ç°¡æ˜“é–¢æ•°"""
    if metadata_generator:
        return metadata_generator.create_short_form_metadata(topic, duration_minutes)
    else:
        logger.warning("Metadata generator not available, using fallback")
        return MetadataGenerator()._get_fallback_shorts_metadata(topic)


if __name__ == "__main__":
    print("Testing metadata generation...")
    if cfg.gemini_api_key:
        test_news = [
            {
                "title": "æ—¥çµŒå¹³å‡æ ªä¾¡ãŒ3æ—¥é€£ç¶šã§ä¸Šæ˜‡ã€å¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°",
                "summary": "æ±äº¬æ ªå¼å¸‚å ´ã§æ—¥çµŒå¹³å‡æ ªä¾¡ãŒå‰æ—¥æ¯”1.8%ä¸Šæ˜‡ã—ã€3æ—¥é€£ç¶šã®ä¸Šæ˜‡ã¨ãªã£ãŸã€‚å¥½èª¿ãªä¼æ¥­æ±ºç®—ã¨æµ·å¤–æŠ•è³‡å®¶ã®è²·ã„ãŒæ”¯ãˆã¨ãªã‚Šã€å¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°ã—ãŸã€‚",
                "source": "æ—¥æœ¬çµŒæ¸ˆæ–°è",
                "impact_level": "high",
                "category": "é‡‘è",
            },
            {
                "title": "ä¸­å¤®éŠ€è¡ŒãŒæ”¿ç­–é‡‘åˆ©ã‚’0.25%å¼•ãä¸Šã’",
                "summary": "æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§æ”¿ç­–é‡‘åˆ©ã‚’0.25%å¼•ãä¸Šã’ã‚‹ã“ã¨ã‚’æ±ºå®šã€‚ã‚¤ãƒ³ãƒ•ãƒ¬æŠ‘åˆ¶ã‚’ç›®çš„ã¨ã—ãŸæªç½®ã§ã€å¸‚å ´ã¯äº‹å‰ã«ç¹”ã‚Šè¾¼ã‚“ã§ã„ãŸã€‚",
                "source": "Bloomberg",
                "impact_level": "high",
                "category": "æ”¿ç­–",
            },
        ]
        try:
            generator = MetadataGenerator()
            print("\n=== é€šå¸¸å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
            metadata = generator.generate_youtube_metadata(test_news, "", "daily")
            print(f"ã‚¿ã‚¤ãƒˆãƒ«: {metadata.get('title')}")
            print(f"ã‚¿ã‚°æ•°: {len(metadata.get('tags', []))}")
            print(f"èª¬æ˜æ–‡é•·: {len(metadata.get('description', ''))}")
            print(f"ã‚«ãƒ†ã‚´ãƒª: {metadata.get('category')}")
            print("\n=== ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
            shorts_metadata = generator.create_short_form_metadata("æ—¥çµŒå¹³å‡é«˜å€¤æ›´æ–°", 1)
            print(f"ã‚·ãƒ§ãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«: {shorts_metadata.get('title')}")
            print(f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: {shorts_metadata.get('hashtags')}")
            print(f"å‹•ç”»ã‚¿ã‚¤ãƒ—: {shorts_metadata.get('video_type')}")
        except Exception as e:
            print(f"Test failed: {e}")
    else:
        print("Gemini API not configured, skipping test")

    print("\n=== ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
    fallback_generator = MetadataGenerator()
    fallback_metadata = fallback_generator._get_fallback_metadata([], "daily")
    print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«: {fallback_metadata.get('title')}")
    print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚°æ•°: {len(fallback_metadata.get('tags', []))}")
