import json
import logging
import re
from datetime import datetime
from typing import Any, Dict, List
import google.generativeai as genai
from .api_rotation import get_rotation_manager
from .config import cfg
from .llm_logging import llm_logging_context, record_llm_interaction
from app.constants.prompts import DEFAULT_VIDEO_MODE_CONTEXT, METADATA_MODE_CONTEXT, METADATA_OTHER_POLICIES_LINES, METADATA_REQUIREMENTS_LINES, METADATA_TITLE_AVOID_EXAMPLES, METADATA_TITLE_POLICY_LINES, METADATA_TITLE_SUCCESS_EXAMPLES, indent_lines, join_lines
logger = logging.getLogger(__name__)

class MetadataGenerator:

    def __init__(self):
        self.client = None
        self._setup_client()

    def _setup_client(self):
        try:
            self.client = None
            logger.info('Metadata generator ready (using shared rotation manager)')
        except Exception as e:
            logger.error(f'Failed to initialize metadata generator: {e}')
            raise

    def generate_youtube_metadata(self, news_items: List[Dict[str, Any]], script_content: str='', mode: str='daily') -> Dict[str, Any]:
        try:
            with llm_logging_context(component='metadata_generation', mode=mode):
                prompt = self._build_metadata_prompt(news_items, script_content, mode)
                response = self._call_gemini_for_metadata(prompt)
                metadata = self._parse_metadata_response(response)
                validated_metadata = self._validate_metadata(metadata, news_items)
                logger.info(f'Generated metadata for {mode} video')
                return validated_metadata
        except Exception as e:
            logger.error(f'Failed to generate metadata: {e}')
            return self._get_fallback_metadata(news_items, mode)

    def _build_metadata_prompt(self, news_items: List[Dict[str, Any]], script_content: str, mode: str) -> str:
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        news_summary = self._create_news_summary(news_items)
        mode_description = METADATA_MODE_CONTEXT.get(mode, DEFAULT_VIDEO_MODE_CONTEXT)
        requirements = join_lines(METADATA_REQUIREMENTS_LINES)
        title_policy = join_lines(METADATA_TITLE_POLICY_LINES)
        success_examples = indent_lines(METADATA_TITLE_SUCCESS_EXAMPLES, prefix='  - ')
        avoid_examples = indent_lines(METADATA_TITLE_AVOID_EXAMPLES, prefix='  - ')
        other_policies = join_lines(METADATA_OTHER_POLICIES_LINES)
        prompt = f"""\nä»¥ä¸‹ã®çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã‹ã‚‰ã€YouTubeå‹•ç”»ç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\nã€å‹•ç”»ã‚¿ã‚¤ãƒ—ã€‘{mode_description}\nã€é…ä¿¡æ—¥ã€‘{current_date}\n\nã€ãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã€‘\n{news_summary}\n\nã€å°æœ¬æŠœç²‹ã€‘\n{(script_content[:500] if script_content else 'å°æœ¬ãƒ‡ãƒ¼ã‚¿ãªã—')}...\n\nã€è¦ä»¶ã€‘\n{requirements}\n\nã€ã‚¿ã‚¤ãƒˆãƒ«ä½œæˆã®é‡è¦æ–¹é‡ã€‘\n{title_policy}\n\nâœ… **æˆåŠŸä¾‹:**\n{success_examples}\n\nâŒ **é¿ã‘ã‚‹ã¹ãä¾‹:**\n{avoid_examples}\n\nã€ãã®ä»–ã®æ–¹é‡ã€‘\n{other_policies}\n\nä»¥ä¸‹ã®JSONå½¢å¼ã§å³å¯†ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š\n```json\n{{\n  "title": "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",\n  "description": "å‹•ç”»èª¬æ˜æ–‡ï¼ˆæ”¹è¡Œã‚’\\nã§è¡¨ç¾ï¼‰",\n  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", "ã‚¿ã‚°3", ...],\n  "category": "YouTube ã‚«ãƒ†ã‚´ãƒª",\n  "thumbnail_text": "ã‚µãƒ ãƒã‚¤ãƒ«ç”¨ãƒ†ã‚­ã‚¹ãƒˆ",\n  "seo_keywords": ["SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...],\n  "target_audience": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¦–è´è€…å±¤",\n  "estimated_watch_time": "æ¨å®šè¦–è´æ™‚é–“ï¼ˆåˆ†ï¼‰"\n}}\n```\n\næ³¨æ„äº‹é …ï¼š\n- å¿…ãšæœ‰åŠ¹ãªJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”\n- ã‚¿ã‚¤ãƒˆãƒ«ã¯é­…åŠ›çš„ã ãŒèª‡å¼µã—ãªã„\n- èª¬æ˜æ–‡ã«ã¯å‡ºå…¸æƒ…å ±ã‚’å«ã‚ã‚‹\n- ã‚¿ã‚°ã¯å…·ä½“çš„ã§æ¤œç´¢æ€§ã®é«˜ã„ã‚‚ã®ã‚’é¸æŠ\n"""
        return prompt

    def _create_news_summary(self, news_items: List[Dict[str, Any]]) -> str:
        if not news_items:
            return 'ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'
        summaries = []
        for i, item in enumerate(news_items, 1):
            summary = f"\nã€ãƒ‹ãƒ¥ãƒ¼ã‚¹{i}ã€‘{item.get('title', 'ç„¡é¡Œ')}\nå‡ºå…¸: {item.get('source', 'ä¸æ˜')}\nè¦ç´„: {item.get('summary', '')[:200]}...\nå½±éŸ¿åº¦: {item.get('impact_level', 'medium')}\n"
            summaries.append(summary)
        return '\n'.join(summaries)

    def _call_gemini_for_metadata(self, prompt: str, max_retries: int=3) -> str:
        rotation_manager = get_rotation_manager()

        def api_call_with_key(api_key: str) -> str:
            try:
                genai.configure(api_key=api_key)
                model_name = cfg.gemini_models.get('metadata_generation')
                client = genai.GenerativeModel(f'models/{model_name}')
                generation_config = genai.GenerationConfig(temperature=0.7, top_p=0.95, top_k=40, max_output_tokens=4096)
                response = client.generate_content(prompt, generation_config=generation_config)
                content = response.text
                logger.debug(f'Generated metadata response length: {len(content)}')
                try:
                    record_llm_interaction(provider='gemini', model=f'models/{model_name}', prompt={'text': prompt, 'generation_config': {'temperature': getattr(generation_config, 'temperature', None), 'top_p': getattr(generation_config, 'top_p', None), 'top_k': getattr(generation_config, 'top_k', None), 'max_output_tokens': getattr(generation_config, 'max_output_tokens', None)}}, response={'text': content}, metadata={'component': 'metadata_generation'})
                except Exception:
                    logger.debug('Failed to log metadata generation interaction', exc_info=True)
                return content
            except Exception as e:
                error_str = str(e).lower()
                if any((kw in error_str for kw in ['429', 'rate limit', 'quota'])):
                    logger.warning(f'Gemini rate limit detected: {e}')
                    raise
                if any((kw in error_str for kw in ['504', 'deadline exceeded', 'timeout'])):
                    logger.warning(f'Gemini timeout detected: {e}')
                    raise
                logger.warning(f'Gemini API error: {e}')
                raise
        try:
            return rotation_manager.execute_with_rotation(provider='gemini', api_call=api_call_with_key, max_attempts=max_retries)
        except Exception as e:
            logger.error(f'All Gemini API attempts failed for metadata generation: {e}')
            raise Exception('Gemini API failed with all keys for metadata generation')

    def _parse_metadata_response(self, response: str) -> Dict[str, Any]:
        try:
            match = re.search('```json\\n(.*?)\\n```', response, re.DOTALL)
            if match:
                json_str = match.group(1)
            else:
                start = response.find('{')
                end = response.rfind('}')
                if start != -1 and end != -1:
                    json_str = response[start:end + 1]
                else:
                    raise ValueError('No JSON structure found')
            metadata = json.loads(json_str)
            return metadata
        except json.JSONDecodeError as e:
            logger.error(f'Failed to parse metadata JSON: {e}')
            logger.debug(f'Raw response: {response[:500]}...')
            return {}
        except Exception as e:
            logger.error(f'Error parsing metadata response: {e}')
            return {}

    def _validate_metadata(self, metadata: Dict[str, Any], news_items: List[Dict[str, Any]]) -> Dict[str, Any]:
        validated = {}
        try:
            title = str(metadata.get('title', '')).strip()
            if len(title) > 50:
                title = title[:47] + '...'
            validated['title'] = title or self._generate_fallback_title(news_items)
            description = str(metadata.get('description', '')).strip()
            description = description.replace('\\n', '\n')
            if len(description) < 100:
                description = self._enhance_description(description, news_items)
            validated['description'] = description
            tags = metadata.get('tags', [])
            if isinstance(tags, list):
                cleaned_tags = []
                for tag in tags[:20]:
                    clean_tag = str(tag).strip()
                    if clean_tag and len(clean_tag) <= 50:
                        cleaned_tags.append(clean_tag)
                validated['tags'] = cleaned_tags
            else:
                validated['tags'] = self._generate_fallback_tags(news_items)
            validated['category'] = str(metadata.get('category', 'News & Politics'))
            validated['thumbnail_text'] = str(metadata.get('thumbnail_text', 'çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹'))
            validated['seo_keywords'] = metadata.get('seo_keywords', [])
            validated['target_audience'] = str(metadata.get('target_audience', 'çµŒæ¸ˆã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…'))
            validated['estimated_watch_time'] = str(metadata.get('estimated_watch_time', '15-30åˆ†'))
            validated['generated_at'] = datetime.now().isoformat()
            validated['news_count'] = len(news_items)
            return validated
        except Exception as e:
            logger.error(f'Metadata validation error: {e}')
            return self._get_fallback_metadata(news_items, 'daily')

    def _generate_fallback_title(self, news_items: List[Dict[str, Any]]) -> str:
        current_date = datetime.now().strftime('%m/%d')
        if news_items and len(news_items) > 0:
            main_topic = news_items[0].get('title', 'çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹')
            wow_keywords = self._extract_wow_elements(main_topic)
            keywords = self._extract_keywords(main_topic)
            if wow_keywords:
                return f"ã€é€Ÿå ±ã€‘{wow_keywords[0]}ï¼æ³¨ç›®ã®{(keywords[0] if keywords else 'çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹')}"
            elif keywords:
                return f'ã€{current_date}ã€‘{keywords[0]}ãŒå‹•ãï¼ä»Šæ—¥ã®é‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹'
        return f'ã€{current_date}é€Ÿå ±ã€‘ä»Šæ—¥ã®çµŒæ¸ˆå¸‚å ´ã§ä½•ãŒèµ·ããŸï¼Ÿ'

    def _extract_wow_elements(self, text: str) -> List[str]:
        wow_elements = []
        percent_match = re.search('([+\\-]?\\d+\\.?\\d*[%ï¼…])', text)
        if percent_match:
            wow_elements.append(f'{percent_match.group(1)}å¤‰å‹•')
        bai_match = re.search('(\\d+\\.?\\d*å€)', text)
        if bai_match:
            wow_elements.append(bai_match.group(1))
        trend_patterns = ['æ€¥é¨°', 'æš´è½', 'æ€¥è½', 'é«˜é¨°', 'æ€¥ä¸Šæ˜‡', 'æ€¥é™ä¸‹', 'å²ä¸Šæœ€é«˜', 'æœ€å®‰å€¤', 'å¹´åˆæ¥é«˜å€¤', 'å¹´åˆæ¥å®‰å€¤']
        for pattern in trend_patterns:
            if pattern in text:
                wow_elements.append(pattern)
                break
        urgent_patterns = ['é€Ÿå ±', 'ç·Šæ€¥', 'è¡æ’ƒ', 'è­¦å‘Š', 'æ³¨ç›®', 'é‡å¤§']
        for pattern in urgent_patterns:
            if pattern in text:
                wow_elements.append(pattern)
                break
        return wow_elements[:2]

    def _enhance_description(self, description: str, news_items: List[Dict[str, Any]]) -> str:
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        enhanced = f'{description}\n\n' if description else ''
        enhanced += f'\nã€{current_date} çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€‘\n\næœ¬æ—¥ã®é‡è¦ãªçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å°‚é–€å®¶ãŒåˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¾ã™ã€‚\n\nğŸ“ˆ ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ï¼š\n'
        for i, item in enumerate(news_items, 1):
            enhanced += f"{i}. {item.get('title', 'ç„¡é¡Œ')}\n"
        enhanced += '\n\nğŸ¯ ã“ã®å‹•ç”»ã§å­¦ã¹ã‚‹ã“ã¨ï¼š\nâ€¢ æœ€æ–°ã®çµŒæ¸ˆå‹•å‘ã¨å¸‚å ´ã¸ã®å½±éŸ¿\nâ€¢ å°‚é–€å®¶ã«ã‚ˆã‚‹è©³ç´°åˆ†æã¨è§£èª¬\nâ€¢ ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆã¨æŠ•è³‡åˆ¤æ–­ææ–™\n\nğŸ“Š ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºï¼š\n'
        sources = set()
        for item in news_items:
            source = item.get('source')
            if source and source != 'ã‚·ã‚¹ãƒ†ãƒ ':
                sources.add(source)
        for source in list(sources)[:5]:
            enhanced += f'â€¢ {source}\n'
        enhanced += '\n\nâš ï¸ å…è²¬äº‹é …ï¼š\næœ¬å‹•ç”»ã®å†…å®¹ã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡å‹§èª˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\næŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚\n\n#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #æ ªå¼å¸‚å ´ #é‡‘è #çµŒæ¸ˆè§£èª¬\n'
        return enhanced

    def _generate_fallback_tags(self, news_items: List[Dict[str, Any]]) -> List[str]:
        base_tags = ['çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æŠ•è³‡', 'æ ªå¼å¸‚å ´', 'é‡‘è', 'çµŒæ¸ˆè§£èª¬', 'ãƒãƒ¼ã‚±ãƒƒãƒˆ', 'çµŒæ¸ˆåˆ†æ', 'ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬']
        for item in news_items:
            title = item.get('title', '')
            keywords = self._extract_keywords(title)
            base_tags.extend(keywords[:3])
        unique_tags = []
        for tag in base_tags:
            if tag not in unique_tags and len(tag) <= 50:
                unique_tags.append(tag)
        return unique_tags[:15]

    def _extract_keywords(self, text: str) -> List[str]:
        economic_patterns = ['æ—¥çµŒå¹³å‡', 'TOPIX', 'ãƒ€ã‚¦', 'ãƒŠã‚¹ãƒ€ãƒƒã‚¯', 'é‡‘åˆ©', 'ã‚¤ãƒ³ãƒ•ãƒ¬', 'GDP', 'å¤±æ¥­ç‡', 'ä¸­å¤®éŠ€è¡Œ', 'æ—¥éŠ€', 'FRB', 'ECB', 'æ ªä¾¡', 'ç‚ºæ›¿', 'å††å®‰', 'å††é«˜', 'ä¼æ¥­æ±ºç®—', 'æ¥­ç¸¾', 'å£²ä¸Š', 'åˆ©ç›Š', 'æ–°è¦ä¸Šå ´', 'IPO', 'M&A', 'è²·å']
        keywords = []
        for pattern in economic_patterns:
            if re.search(pattern, text):
                keywords.append(pattern.replace('\\b', '').replace('\\\\', ''))
        return keywords[:5]

    def _get_fallback_metadata(self, news_items: List[Dict[str, Any]], mode: str) -> Dict[str, Any]:
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        fallback_title = self._generate_fallback_title(news_items)
        return {'title': fallback_title, 'description': f'\nã€{current_date} çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€‘\n\næœ¬æ—¥ã®é‡è¦ãªçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å°‚é–€å®¶ãŒåˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¾ã™ã€‚\n\nğŸ“ˆ ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ï¼š\n' + '\n'.join([f"â€¢ {item.get('title', 'ç„¡é¡Œ')}" for item in news_items[:3]]) + '\n\nğŸ¯ ã“ã®å‹•ç”»ã§å­¦ã¹ã‚‹ã“ã¨ï¼š\nâ€¢ æœ€æ–°ã®çµŒæ¸ˆå‹•å‘ã¨å¸‚å ´ã¸ã®å½±éŸ¿\nâ€¢ å°‚é–€å®¶ã«ã‚ˆã‚‹è©³ç´°åˆ†æã¨è§£èª¬\nâ€¢ ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ\n\nâš ï¸ å…è²¬äº‹é …ï¼š\næœ¬å‹•ç”»ã®å†…å®¹ã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡å‹§èª˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\n#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #æ ªå¼å¸‚å ´ #é‡‘è #çµŒæ¸ˆè§£èª¬', 'tags': self._generate_fallback_tags(news_items), 'category': 'News & Politics', 'thumbnail_text': 'çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬', 'seo_keywords': ['çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æŠ•è³‡', 'æ ªå¼å¸‚å ´', 'é‡‘è'], 'target_audience': 'çµŒæ¸ˆã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…', 'estimated_watch_time': '15-30åˆ†', 'generated_at': datetime.now().isoformat(), 'news_count': len(news_items), 'fallback': True}

    def create_short_form_metadata(self, topic: str, duration_minutes: int=1) -> Dict[str, Any]:
        prompt = f'\nä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€YouTube Shortsç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š\n\nãƒˆãƒ”ãƒƒã‚¯: {topic}\nå‹•ç”»é•·: {duration_minutes}åˆ†\n\nè¦ä»¶ï¼š\n- ã‚¿ã‚¤ãƒˆãƒ«: 30æ–‡å­—ä»¥å†…ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆé‡è¦–\n- èª¬æ˜æ–‡: 500æ–‡å­—ä»¥å†…ã€ç°¡æ½”ã§èˆˆå‘³ã‚’å¼•ã\n- ã‚¿ã‚°: ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å‘ã‘ã€10å€‹ç¨‹åº¦\n- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: ãƒˆãƒ¬ãƒ³ãƒ‰æ€§é‡è¦–\n\nJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š\n{{\n  "title": "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«",\n  "description": "ç°¡æ½”ãªèª¬æ˜æ–‡",\n  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", ...],\n  "hashtags": ["#ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°1", "#ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°2", ...],\n  "category": "News & Politics"\n}}\n'
        try:
            response = self._call_gemini_for_metadata(prompt)
            metadata = self._parse_metadata_response(response)
            if metadata:
                metadata['video_type'] = 'shorts'
                metadata['estimated_watch_time'] = f'{duration_minutes}åˆ†'
                metadata['generated_at'] = datetime.now().isoformat()
            return metadata or self._get_fallback_shorts_metadata(topic)
        except Exception as e:
            logger.error(f'Failed to generate shorts metadata: {e}')
            return self._get_fallback_shorts_metadata(topic)

    def _get_fallback_shorts_metadata(self, topic: str) -> Dict[str, Any]:
        return {'title': f'ã€é€Ÿå ±ã€‘{topic}', 'description': f'{topic}ã«ã¤ã„ã¦1åˆ†ã§è§£èª¬\n\n#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»', 'tags': ['çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æŠ•è³‡', 'ã‚·ãƒ§ãƒ¼ãƒˆ', 'é€Ÿå ±', topic], 'hashtags': ['#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹', '#æŠ•è³‡', '#ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»', '#é€Ÿå ±'], 'category': 'News & Politics', 'video_type': 'shorts', 'estimated_watch_time': '1åˆ†', 'generated_at': datetime.now().isoformat(), 'fallback': True}
metadata_generator = MetadataGenerator() if cfg.gemini_api_key else None

def generate_youtube_metadata(news_items: List[Dict[str, Any]], script_content: str='', mode: str='daily') -> Dict[str, Any]:
    if metadata_generator:
        return metadata_generator.generate_youtube_metadata(news_items, script_content, mode)
    else:
        logger.warning('Metadata generator not available, using fallback')
        return MetadataGenerator()._get_fallback_metadata(news_items, mode)

def create_shorts_metadata(topic: str, duration_minutes: int=1) -> Dict[str, Any]:
    if metadata_generator:
        return metadata_generator.create_short_form_metadata(topic, duration_minutes)
    else:
        logger.warning('Metadata generator not available, using fallback')
        return MetadataGenerator()._get_fallback_shorts_metadata(topic)
if __name__ == '__main__':
    print('Testing metadata generation...')
    if cfg.gemini_api_key:
        test_news = [{'title': 'æ—¥çµŒå¹³å‡æ ªä¾¡ãŒ3æ—¥é€£ç¶šã§ä¸Šæ˜‡ã€å¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°', 'summary': 'æ±äº¬æ ªå¼å¸‚å ´ã§æ—¥çµŒå¹³å‡æ ªä¾¡ãŒå‰æ—¥æ¯”1.8%ä¸Šæ˜‡ã—ã€3æ—¥é€£ç¶šã®ä¸Šæ˜‡ã¨ãªã£ãŸã€‚å¥½èª¿ãªä¼æ¥­æ±ºç®—ã¨æµ·å¤–æŠ•è³‡å®¶ã®è²·ã„ãŒæ”¯ãˆã¨ãªã‚Šã€å¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°ã—ãŸã€‚', 'source': 'æ—¥æœ¬çµŒæ¸ˆæ–°è', 'impact_level': 'high', 'category': 'é‡‘è'}, {'title': 'ä¸­å¤®éŠ€è¡ŒãŒæ”¿ç­–é‡‘åˆ©ã‚’0.25%å¼•ãä¸Šã’', 'summary': 'æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§æ”¿ç­–é‡‘åˆ©ã‚’0.25%å¼•ãä¸Šã’ã‚‹ã“ã¨ã‚’æ±ºå®šã€‚ã‚¤ãƒ³ãƒ•ãƒ¬æŠ‘åˆ¶ã‚’ç›®çš„ã¨ã—ãŸæªç½®ã§ã€å¸‚å ´ã¯äº‹å‰ã«ç¹”ã‚Šè¾¼ã‚“ã§ã„ãŸã€‚', 'source': 'Bloomberg', 'impact_level': 'high', 'category': 'æ”¿ç­–'}]
        try:
            generator = MetadataGenerator()
            print('\n=== é€šå¸¸å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===')
            metadata = generator.generate_youtube_metadata(test_news, '', 'daily')
            print(f"ã‚¿ã‚¤ãƒˆãƒ«: {metadata.get('title')}")
            print(f"ã‚¿ã‚°æ•°: {len(metadata.get('tags', []))}")
            print(f"èª¬æ˜æ–‡é•·: {len(metadata.get('description', ''))}")
            print(f"ã‚«ãƒ†ã‚´ãƒª: {metadata.get('category')}")
            print('\n=== ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===')
            shorts_metadata = generator.create_short_form_metadata('æ—¥çµŒå¹³å‡é«˜å€¤æ›´æ–°', 1)
            print(f"ã‚·ãƒ§ãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«: {shorts_metadata.get('title')}")
            print(f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: {shorts_metadata.get('hashtags')}")
            print(f"å‹•ç”»ã‚¿ã‚¤ãƒ—: {shorts_metadata.get('video_type')}")
        except Exception as e:
            print(f'Test failed: {e}')
    else:
        print('Gemini API not configured, skipping test')
    print('\n=== ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===')
    fallback_generator = MetadataGenerator()
    fallback_metadata = fallback_generator._get_fallback_metadata([], 'daily')
    print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«: {fallback_metadata.get('title')}")
    print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚°æ•°: {len(fallback_metadata.get('tags', []))}")