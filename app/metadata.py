""" ""
ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

YouTubeå‹•ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«ã€èª¬æ˜æ–‡ã€ã‚¿ã‚°ã€ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚
SEOæœ€é©åŒ–ã¨è¦–è´è€…ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‘ä¸Šã‚’ç›®çš„ã¨ã—ãŸé«˜å“è³ªãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™ã€‚
"""

import json
import logging
import re
from datetime import datetime
from typing import Any, Dict, List

import google.generativeai as genai

from config import cfg

logger = logging.getLogger(__name__)


class MetadataGenerator:
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.client = None
        self._setup_client()

    def _setup_client(self):
        """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            if not cfg.gemini_api_key:
                raise ValueError("Gemini API key not configured")

            genai.configure(api_key=cfg.gemini_api_key)
            self.client = genai.GenerativeModel("gemini-1.5-flash-latest")
            logger.info("Metadata generator initialized with Gemini")

        except Exception as e:
            logger.error(f"Failed to initialize metadata generator: {e}")
            raise

    def generate_youtube_metadata(
        self, news_items: List[Dict[str, Any]], script_content: str = "", mode: str = "daily"
    ) -> Dict[str, Any]:
        """YouTubeå‹•ç”»ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        try:
            prompt = self._build_metadata_prompt(news_items, script_content, mode)
            response = self._call_gemini_for_metadata(prompt)
            metadata = self._parse_metadata_response(response)
            validated_metadata = self._validate_metadata(metadata, news_items)
            logger.info(f"Generated metadata for {mode} video")
            return validated_metadata
        except Exception as e:
            logger.error(f"Failed to generate metadata: {e}")
            return self._get_fallback_metadata(news_items, mode)

    def _build_metadata_prompt(self, news_items: List[Dict[str, Any]], script_content: str, mode: str) -> str:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        news_summary = self._create_news_summary(news_items)
        mode_context = {
            "daily": "æ—¥æ¬¡ã®çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬å‹•ç”»",
            "special": "ç‰¹é›†ãƒ»æ·±å €ã‚Šè§£èª¬å‹•ç”»",
            "breaking": "é€Ÿå ±ãƒ»ç·Šæ€¥ãƒ‹ãƒ¥ãƒ¼ã‚¹å‹•ç”»",
        }
        prompt = f"""
ä»¥ä¸‹ã®çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã‹ã‚‰ã€YouTubeå‹•ç”»ç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€å‹•ç”»ã‚¿ã‚¤ãƒ—ã€‘{mode_context.get(mode, "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬å‹•ç”»")}
ã€é…ä¿¡æ—¥ã€‘{current_date}

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã€‘
{news_summary}

ã€å°æœ¬æŠœç²‹ã€‘
{script_content[:500] if script_content else "å°æœ¬ãƒ‡ãƒ¼ã‚¿ãªã—"}...

ã€è¦ä»¶ã€‘
1. ã‚¿ã‚¤ãƒˆãƒ«: 50æ–‡å­—ä»¥å†…ã€ã‚¯ãƒªãƒƒã‚¯ç‡å‘ä¸Šã‚’æ„è­˜
2. èª¬æ˜æ–‡: 1000-3000æ–‡å­—ã€SEOæœ€é©åŒ–
3. ã‚¿ã‚°: 15-20å€‹ã€æ¤œç´¢æ€§å‘ä¸Š
4. ã‚«ãƒ†ã‚´ãƒª: YouTubeæ¨™æº–ã‚«ãƒ†ã‚´ãƒª
5. ã‚µãƒ ãƒã‚¤ãƒ«æ–‡è¨€: å¤§ããè¡¨ç¤ºã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

ã€é‡è¦ãªæ–¹é‡ã€‘
- æ­£ç¢ºæ€§ã¨ä¿¡é ¼æ€§ã‚’æœ€å„ªå…ˆ
- ç…½ã‚Šã™ããªã„ã€å“æ ¼ã‚’ä¿ã¤
- æ¤œç´¢ã•ã‚Œã‚„ã™ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
- è¦–è´è€…ä¾¡å€¤ã‚’æ˜ç¢ºã«ç¤ºã™
- æ™‚äº‹æ€§ã‚’å¼·èª¿

ä»¥ä¸‹ã®JSONå½¢å¼ã§å³å¯†ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
  "title": "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",
  "description": "å‹•ç”»èª¬æ˜æ–‡ï¼ˆæ”¹è¡Œã‚’\\nã§è¡¨ç¾ï¼‰",
  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", "ã‚¿ã‚°3", ...],
  "category": "YouTube ã‚«ãƒ†ã‚´ãƒª",
  "thumbnail_text": "ã‚µãƒ ãƒã‚¤ãƒ«ç”¨ãƒ†ã‚­ã‚¹ãƒˆ",
  "seo_keywords": ["SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...],
  "target_audience": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¦–è´è€…å±¤",
  "estimated_watch_time": "æ¨å®šè¦–è´æ™‚é–“ï¼ˆåˆ†ï¼‰"
}}
```

æ³¨æ„äº‹é …ï¼š
- å¿…ãšæœ‰åŠ¹ãªJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”
- ã‚¿ã‚¤ãƒˆãƒ«ã¯é­…åŠ›çš„ã ãŒèª‡å¼µã—ãªã„
- èª¬æ˜æ–‡ã«ã¯å‡ºå…¸æƒ…å ±ã‚’å«ã‚ã‚‹
- ã‚¿ã‚°ã¯å…·ä½“çš„ã§æ¤œç´¢æ€§ã®é«˜ã„ã‚‚ã®ã‚’é¸æŠ
"""
        return prompt

    def _create_news_summary(self, news_items: List[Dict[str, Any]]) -> str:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã‹ã‚‰è¦ç´„ã‚’ä½œæˆ"""
        if not news_items:
            return "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        summaries = []
        for i, item in enumerate(news_items, 1):
            summary = f"""
ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹{i}ã€‘{item.get("title", "ç„¡é¡Œ")}
å‡ºå…¸: {item.get("source", "ä¸æ˜")}
è¦ç´„: {item.get("summary", "")[:200]}...
å½±éŸ¿åº¦: {item.get("impact_level", "medium")}
"""
            summaries.append(summary)
        return "\n".join(summaries)

    def _call_gemini_for_metadata(self, prompt: str, max_retries: int = 3) -> str:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆç”¨Gemini APIå‘¼ã³å‡ºã—"""
        import random
        import time

        for attempt in range(max_retries):
            try:
                response = self.client.generate_content(prompt)
                content = response.text
                logger.debug(f"Generated metadata response length: {len(content)}")
                return content
            except Exception as e:
                if "rate_limit" in str(e).lower() and attempt < max_retries - 1:
                    wait_time = (2**attempt) + random.uniform(0, 1)
                    logger.warning(f"Rate limit hit, waiting {wait_time:.2f}s...")
                    time.sleep(wait_time)
                    continue
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"Metadata generation error, retrying in {wait_time}s: {e}")
                    time.sleep(wait_time)
                    continue
                raise
        raise Exception("Max retries exceeded for metadata generation")

    def _parse_metadata_response(self, response: str) -> Dict[str, Any]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ"""
        try:
            match = re.search(r"```json\n(.*?)\n```", response, re.DOTALL)
            if match:
                json_str = match.group(1)
            else:
                start = response.find("{")
                end = response.rfind("}")
                if start != -1 and end != -1:
                    json_str = response[start : end + 1]
                else:
                    raise ValueError("No JSON structure found")
            metadata = json.loads(json_str)
            return metadata
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse metadata JSON: {e}")
            logger.debug(f"Raw response: {response[:500]}...")
            return {}
        except Exception as e:
            logger.error(f"Error parsing metadata response: {e}")
            return {}

    def _validate_metadata(self, metadata: Dict[str, Any], news_items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        validated = {}
        try:
            title = str(metadata.get("title", "")).strip()
            if len(title) > 50:
                title = title[:47] + "..."
            validated["title"] = title or self._generate_fallback_title(news_items)
            description = str(metadata.get("description", "")).strip()
            description = description.replace("\\n", "\n")
            if len(description) < 100:
                description = self._enhance_description(description, news_items)
            validated["description"] = description
            tags = metadata.get("tags", [])
            if isinstance(tags, list):
                cleaned_tags = []
                for tag in tags[:20]:
                    clean_tag = str(tag).strip()
                    if clean_tag and len(clean_tag) <= 50:
                        cleaned_tags.append(clean_tag)
                validated["tags"] = cleaned_tags
            else:
                validated["tags"] = self._generate_fallback_tags(news_items)
            validated["category"] = str(metadata.get("category", "News & Politics"))
            validated["thumbnail_text"] = str(metadata.get("thumbnail_text", "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹"))
            validated["seo_keywords"] = metadata.get("seo_keywords", [])
            validated["target_audience"] = str(metadata.get("target_audience", "çµŒæ¸ˆã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…"))
            validated["estimated_watch_time"] = str(metadata.get("estimated_watch_time", "15-30åˆ†"))
            validated["generated_at"] = datetime.now().isoformat()
            validated["news_count"] = len(news_items)
            return validated
        except Exception as e:
            logger.error(f"Metadata validation error: {e}")
            return self._get_fallback_metadata(news_items, "daily")

    def _generate_fallback_title(self, news_items: List[Dict[str, Any]]) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        current_date = datetime.now().strftime("%m/%d")
        if news_items and len(news_items) > 0:
            main_topic = news_items[0].get("title", "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹")
            keywords = self._extract_keywords(main_topic)
            if keywords:
                return f"ã€{current_date}ã€‘{keywords[0]}ãªã©é‡è¦çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬"
        return f"ã€{current_date}ã€‘ä»Šæ—¥ã®é‡è¦çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬"

    def _enhance_description(self, description: str, news_items: List[Dict[str, Any]]) -> str:
        """èª¬æ˜æ–‡ã‚’æ‹¡å……"""
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        enhanced = f"{description}\n\n" if description else ""
        enhanced += f"""
ã€{current_date} çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€‘

æœ¬æ—¥ã®é‡è¦ãªçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å°‚é–€å®¶ãŒåˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¾ã™ã€‚

ğŸ“ˆ ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ï¼š
"""
        for i, item in enumerate(news_items, 1):
            enhanced += f"{i}. {item.get('title', 'ç„¡é¡Œ')}\n"
        enhanced += """

ğŸ¯ ã“ã®å‹•ç”»ã§å­¦ã¹ã‚‹ã“ã¨ï¼š
â€¢ æœ€æ–°ã®çµŒæ¸ˆå‹•å‘ã¨å¸‚å ´ã¸ã®å½±éŸ¿
â€¢ å°‚é–€å®¶ã«ã‚ˆã‚‹è©³ç´°åˆ†æã¨è§£èª¬
â€¢ ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆã¨æŠ•è³‡åˆ¤æ–­ææ–™

ğŸ“Š ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºï¼š
"""
        sources = set()
        for item in news_items:
            source = item.get("source")
            if source and source != "ã‚·ã‚¹ãƒ†ãƒ ":
                sources.add(source)
        for source in list(sources)[:5]:
            enhanced += f"â€¢ {source}\n"
        enhanced += """

âš ï¸ å…è²¬äº‹é …ï¼š
æœ¬å‹•ç”»ã®å†…å®¹ã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡å‹§èª˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚

#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #æ ªå¼å¸‚å ´ #é‡‘è #çµŒæ¸ˆè§£èª¬
"""
        return enhanced

    def _generate_fallback_tags(self, news_items: List[Dict[str, Any]]) -> List[str]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚¿ã‚°ç”Ÿæˆ"""
        base_tags = ["çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "æŠ•è³‡", "æ ªå¼å¸‚å ´", "é‡‘è", "çµŒæ¸ˆè§£èª¬", "ãƒãƒ¼ã‚±ãƒƒãƒˆ", "çµŒæ¸ˆåˆ†æ", "ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬"]
        for item in news_items:
            title = item.get("title", "")
            keywords = self._extract_keywords(title)
            base_tags.extend(keywords[:3])
        unique_tags = []
        for tag in base_tags:
            if tag not in unique_tags and len(tag) <= 50:
                unique_tags.append(tag)
        return unique_tags[:15]

    def _extract_keywords(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        economic_patterns = [
            r"æ—¥çµŒå¹³å‡",
            r"TOPIX",
            r"ãƒ€ã‚¦",
            r"ãƒŠã‚¹ãƒ€ãƒƒã‚¯",
            r"é‡‘åˆ©",
            r"ã‚¤ãƒ³ãƒ•ãƒ¬",
            r"GDP",
            r"å¤±æ¥­ç‡",
            r"ä¸­å¤®éŠ€è¡Œ",
            r"æ—¥éŠ€",
            r"FRB",
            r"ECB",
            r"æ ªä¾¡",
            r"ç‚ºæ›¿",
            r"å††å®‰",
            r"å††é«˜",
            r"ä¼æ¥­æ±ºç®—",
            r"æ¥­ç¸¾",
            r"å£²ä¸Š",
            r"åˆ©ç›Š",
            r"æ–°è¦ä¸Šå ´",
            r"IPO",
            r"M&A",
            r"è²·å",
        ]
        keywords = []
        for pattern in economic_patterns:
            if re.search(pattern, text):
                keywords.append(pattern.replace(r"\b", "").replace(r"\\", ""))
        return keywords[:5]

    def _get_fallback_metadata(self, news_items: List[Dict[str, Any]], mode: str) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        return {
            "title": f"ã€{current_date}ã€‘é‡è¦çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬",
            "description": f"""
ã€{current_date} çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€‘

æœ¬æ—¥ã®é‡è¦ãªçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å°‚é–€å®¶ãŒåˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¾ã™ã€‚

ğŸ“ˆ ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ï¼š
"""
            + "\n".join([f"â€¢ {item.get('title', 'ç„¡é¡Œ')}" for item in news_items[:3]])
            + """

ğŸ¯ ã“ã®å‹•ç”»ã§å­¦ã¹ã‚‹ã“ã¨ï¼š
â€¢ æœ€æ–°ã®çµŒæ¸ˆå‹•å‘ã¨å¸‚å ´ã¸ã®å½±éŸ¿
â€¢ å°‚é–€å®¶ã«ã‚ˆã‚‹è©³ç´°åˆ†æã¨è§£èª¬
â€¢ ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ

âš ï¸ å…è²¬äº‹é …ï¼š
æœ¬å‹•ç”»ã®å†…å®¹ã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡å‹§èª˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #æ ªå¼å¸‚å ´ #é‡‘è #çµŒæ¸ˆè§£èª¬""",
            "tags": self._generate_fallback_tags(news_items),
            "category": "News & Politics",
            "thumbnail_text": "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬",
            "seo_keywords": ["çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "æŠ•è³‡", "æ ªå¼å¸‚å ´", "é‡‘è"],
            "target_audience": "çµŒæ¸ˆã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…",
            "estimated_watch_time": "15-30åˆ†",
            "generated_at": datetime.now().isoformat(),
            "news_count": len(news_items),
            "fallback": True,
        }

    def create_short_form_metadata(self, topic: str, duration_minutes: int = 1) -> Dict[str, Any]:
        """ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€YouTube Shortsç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

ãƒˆãƒ”ãƒƒã‚¯: {topic}
å‹•ç”»é•·: {duration_minutes}åˆ†

è¦ä»¶ï¼š
- ã‚¿ã‚¤ãƒˆãƒ«: 30æ–‡å­—ä»¥å†…ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆé‡è¦–
- èª¬æ˜æ–‡: 500æ–‡å­—ä»¥å†…ã€ç°¡æ½”ã§èˆˆå‘³ã‚’å¼•ã
- ã‚¿ã‚°: ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å‘ã‘ã€10å€‹ç¨‹åº¦
- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: ãƒˆãƒ¬ãƒ³ãƒ‰æ€§é‡è¦–

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "title": "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«",
  "description": "ç°¡æ½”ãªèª¬æ˜æ–‡",
  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", ...],
  "hashtags": ["#ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°1", "#ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°2", ...],
  "category": "News & Politics"
}}
"""
        try:
            response = self._call_gemini_for_metadata(prompt)
            metadata = self._parse_metadata_response(response)
            if metadata:
                metadata["video_type"] = "shorts"
                metadata["estimated_watch_time"] = f"{duration_minutes}åˆ†"
                metadata["generated_at"] = datetime.now().isoformat()
            return metadata or self._get_fallback_shorts_metadata(topic)
        except Exception as e:
            logger.error(f"Failed to generate shorts metadata: {e}")
            return self._get_fallback_shorts_metadata(topic)

    def _get_fallback_shorts_metadata(self, topic: str) -> Dict[str, Any]:
        """ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
        return {
            "title": f"ã€é€Ÿå ±ã€‘{topic}",
            "description": f"{topic}ã«ã¤ã„ã¦1åˆ†ã§è§£èª¬\n\n#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ #æŠ•è³‡ #ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»",
            "tags": ["çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "æŠ•è³‡", "ã‚·ãƒ§ãƒ¼ãƒˆ", "é€Ÿå ±", topic],
            "hashtags": ["#çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹", "#æŠ•è³‡", "#ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»", "#é€Ÿå ±"],
            "category": "News & Politics",
            "video_type": "shorts",
            "estimated_watch_time": "1åˆ†",
            "generated_at": datetime.now().isoformat(),
            "fallback": True,
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
metadata_generator = MetadataGenerator() if cfg.gemini_api_key else None


def generate_youtube_metadata(
    news_items: List[Dict[str, Any]], script_content: str = "", mode: str = "daily"
) -> Dict[str, Any]:
    """YouTube ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ç°¡æ˜“é–¢æ•°"""
    if metadata_generator:
        return metadata_generator.generate_youtube_metadata(news_items, script_content, mode)
    else:
        logger.warning("Metadata generator not available, using fallback")
        return MetadataGenerator()._get_fallback_metadata(news_items, mode)


def create_shorts_metadata(topic: str, duration_minutes: int = 1) -> Dict[str, Any]:
    """ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ç°¡æ˜“é–¢æ•°"""
    if metadata_generator:
        return metadata_generator.create_short_form_metadata(topic, duration_minutes)
    else:
        logger.warning("Metadata generator not available, using fallback")
        return MetadataGenerator()._get_fallback_shorts_metadata(topic)


if __name__ == "__main__":
    print("Testing metadata generation...")
    if cfg.gemini_api_key:
        test_news = [
            {
                "title": "æ—¥çµŒå¹³å‡æ ªä¾¡ãŒ3æ—¥é€£ç¶šã§ä¸Šæ˜‡ã€å¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°",
                "summary": "æ±äº¬æ ªå¼å¸‚å ´ã§æ—¥çµŒå¹³å‡æ ªä¾¡ãŒå‰æ—¥æ¯”1.8%ä¸Šæ˜‡ã—ã€3æ—¥é€£ç¶šã®ä¸Šæ˜‡ã¨ãªã£ãŸã€‚å¥½èª¿ãªä¼æ¥­æ±ºç®—ã¨æµ·å¤–æŠ•è³‡å®¶ã®è²·ã„ãŒæ”¯ãˆã¨ãªã‚Šã€å¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°ã—ãŸã€‚",
                "source": "æ—¥æœ¬çµŒæ¸ˆæ–°è",
                "impact_level": "high",
                "category": "é‡‘è",
            },
            {
                "title": "ä¸­å¤®éŠ€è¡ŒãŒæ”¿ç­–é‡‘åˆ©ã‚’0.25%å¼•ãä¸Šã’",
                "summary": "æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§æ”¿ç­–é‡‘åˆ©ã‚’0.25%å¼•ãä¸Šã’ã‚‹ã“ã¨ã‚’æ±ºå®šã€‚ã‚¤ãƒ³ãƒ•ãƒ¬æŠ‘åˆ¶ã‚’ç›®çš„ã¨ã—ãŸæªç½®ã§ã€å¸‚å ´ã¯äº‹å‰ã«ç¹”ã‚Šè¾¼ã‚“ã§ã„ãŸã€‚",
                "source": "Bloomberg",
                "impact_level": "high",
                "category": "æ”¿ç­–",
            },
        ]
        try:
            generator = MetadataGenerator()
            print("\n=== é€šå¸¸å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
            metadata = generator.generate_youtube_metadata(test_news, "", "daily")
            print(f"ã‚¿ã‚¤ãƒˆãƒ«: {metadata.get('title')}")
            print(f"ã‚¿ã‚°æ•°: {len(metadata.get('tags', []))}")
            print(f"èª¬æ˜æ–‡é•·: {len(metadata.get('description', ''))}")
            print(f"ã‚«ãƒ†ã‚´ãƒª: {metadata.get('category')}")
            print("\n=== ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
            shorts_metadata = generator.create_short_form_metadata("æ—¥çµŒå¹³å‡é«˜å€¤æ›´æ–°", 1)
            print(f"ã‚·ãƒ§ãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«: {shorts_metadata.get('title')}")
            print(f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: {shorts_metadata.get('hashtags')}")
            print(f"å‹•ç”»ã‚¿ã‚¤ãƒ—: {shorts_metadata.get('video_type')}")
        except Exception as e:
            print(f"Test failed: {e}")
    else:
        print("Gemini API not configured, skipping test")

    print("\n=== ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
    fallback_generator = MetadataGenerator()
    fallback_metadata = fallback_generator._get_fallback_metadata([], "daily")
    print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«: {fallback_metadata.get('title')}")
    print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚°æ•°: {len(fallback_metadata.get('tags', []))}")
