"""Phase 1-A åŸºç›¤æ•´å‚™ã®ãƒ†ã‚¹ãƒˆ

ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã€è¨­å®šã€AI Clientã®å‹•ä½œç¢ºèª
"""

import asyncio
from pprint import pprint


def test_data_models():
    """ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("TEST 1: Data Models")
    print("=" * 60)

    from app.models import NewsItem, NewsCollection, Script, ScriptSegment, QualityScore, WOWMetrics

    # NewsItemä½œæˆ
    news = NewsItem(
        title="æ—¥çµŒå¹³å‡ãŒå¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°",
        url="https://example.com/news1",
        summary="æ±äº¬æ ªå¼å¸‚å ´ã§æ—¥çµŒå¹³å‡æ ªä¾¡ãŒå‰æ—¥æ¯”2.1%ä¸Šæ˜‡ã—ã€å¹´åˆæ¥é«˜å€¤ã‚’æ›´æ–°ã—ãŸã€‚å¥½èª¿ãªä¼æ¥­æ±ºç®—ã¨æµ·å¤–æŠ•è³‡å®¶ã®è²·ã„ãŒæ”¯ãˆã¨ãªã£ãŸã€‚",
        key_points=["å¹´åˆæ¥é«˜å€¤æ›´æ–°", "2.1%ä¸Šæ˜‡", "å¥½èª¿ãªä¼æ¥­æ±ºç®—"],
        source="æ—¥æœ¬çµŒæ¸ˆæ–°è",
        impact_level="high",
        category="é‡‘è"
    )

    print(f"âœ“ NewsItemä½œæˆæˆåŠŸ")
    print(f"  - Title: {news.title}")
    print(f"  - High Impact: {news.is_high_impact}")

    # NewsCollectionä½œæˆ
    collection = NewsCollection(
        items=[news],
        mode="test"
    )

    print(f"âœ“ NewsCollectionä½œæˆæˆåŠŸ")
    print(f"  - Mode: {collection.mode}")
    print(f"  - Count: {collection.total_count}")
    print(f"  - Has High Impact: {collection.has_high_impact}")

    # ScriptSegmentä½œæˆ
    segment = ScriptSegment(
        speaker="ç”°ä¸­",
        text="ä»Šæ—¥ã®å¸‚å ´å‹•å‘ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™",
        visual_instruction="ã‚°ãƒ©ãƒ•: æ—¥çµŒå¹³å‡æ¨ç§»"
    )

    print(f"âœ“ ScriptSegmentä½œæˆæˆåŠŸ")
    print(f"  - Speaker: {segment.speaker}")
    print(f"  - Text: {segment.text}")
    print(f"  - Char Count: {segment.char_count}")

    # QualityScoreä½œæˆ
    score = QualityScore(
        wow_score=8.5,
        surprise_score=9.0,
        emotion_score=8.0,
        clarity_score=8.5,
        retention_prediction=54.0,
        japanese_purity=97.5
    )

    print(f"âœ“ QualityScoreä½œæˆæˆåŠŸ")
    print(f"  - WOW Score: {score.wow_score}")
    print(f"  - Is Passing: {score.is_passing()}")
    print(f"  - Is Excellent: {score.is_excellent}")

    print()
    return True


def test_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("TEST 2: Configuration")
    print("=" * 60)

    from app.config import settings

    print(f"âœ“ è¨­å®šèª­ã¿è¾¼ã¿æˆåŠŸ")
    print(f"  - Speakers: {len(settings.speakers)}")
    print(f"  - Video Resolution: {settings.video.resolution_tuple}")
    print(f"  - WOW Score Min: {settings.quality_thresholds.wow_score_min}")
    print(f"  - CrewAI Enabled: {settings.crew.enabled}")

    # è©±è€…è¨­å®š
    tanaka = settings.get_speaker_config("ç”°ä¸­")
    if tanaka:
        print(f"  - ç”°ä¸­: {tanaka.role}")

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
    agent_config = settings.get_agent_config("deep_news_analyzer")
    if agent_config:
        print(f"  - Deep News Analyzer Model: {agent_config.model}")
        print(f"  - Temperature: {agent_config.temperature}")

    print()
    return True


def test_prompt_manager():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("TEST 3: Prompt Manager")
    print("=" * 60)

    from app.config.prompts import get_prompt_manager

    manager = get_prompt_manager()

    # agents.yamlã®èª­ã¿è¾¼ã¿
    try:
        agents_data = manager.load("agents.yaml")
        print(f"âœ“ agents.yamlèª­ã¿è¾¼ã¿æˆåŠŸ")
        print(f"  - Agents: {len(agents_data.get('agents', {}))}")

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šå–å¾—
        deep_analyzer_config = manager.get_agent_config("deep_news_analyzer")
        print(f"  - Deep News Analyzer Role: {deep_analyzer_config['role']}")

    except Exception as e:
        print(f"âœ— agents.yamlèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return False

    # analysis.yamlã®èª­ã¿è¾¼ã¿
    try:
        analysis_data = manager.load("analysis.yaml")
        print(f"âœ“ analysis.yamlèª­ã¿è¾¼ã¿æˆåŠŸ")
        print(f"  - Tasks: {len(analysis_data.get('tasks', {}))}")
    except Exception as e:
        print(f"âœ— analysis.yamlèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return False

    print()
    return True


def test_ai_clients():
    """AI Clientã®ãƒ†ã‚¹ãƒˆï¼ˆAPI Keyç¢ºèªã®ã¿ï¼‰"""
    print("=" * 60)
    print("TEST 4: AI Clients")
    print("=" * 60)

    from app.config import settings

    # API Keyã®å­˜åœ¨ç¢ºèª
    gemini_key = settings.api_keys.get('gemini')
    perplexity_key = settings.api_keys.get('perplexity')

    if gemini_key:
        print(f"âœ“ Gemini API Key configured: {gemini_key[:10]}...")

        # GeminiClientã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ãƒ†ã‚¹ãƒˆ
        try:
            from app.crew.tools import get_gemini_client
            client = get_gemini_client(temperature=0.7)
            print(f"  - GeminiClient instance created successfully")
            print(f"  - Model: {client.model_name}")
            print(f"  - Temperature: {client.temperature}")
        except Exception as e:
            print(f"âœ— GeminiClient creation failed: {e}")
            return False
    else:
        print(f"âš  Gemini API Key not found (skipping client test)")

    if perplexity_key:
        print(f"âœ“ Perplexity API Key configured: {perplexity_key[:10]}...")
        try:
            from app.crew.tools import get_perplexity_client
            client = get_perplexity_client()
            print(f"  - PerplexityClient instance created successfully")
            print(f"  - Model: {client.model}")
        except Exception as e:
            print(f"âœ— PerplexityClient creation failed: {e}")
            return False
    else:
        print(f"âš  Perplexity API Key not found (skipping client test)")

    print()
    return True


def main():
    """å…¨ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("\n" + "=" * 60)
    print("Phase 1-A: åŸºç›¤æ•´å‚™ ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 60 + "\n")

    results = []

    # Test 1: Data Models
    try:
        results.append(("Data Models", test_data_models()))
    except Exception as e:
        print(f"âœ— Data Models Test Failed: {e}\n")
        results.append(("Data Models", False))

    # Test 2: Configuration
    try:
        results.append(("Configuration", test_config()))
    except Exception as e:
        print(f"âœ— Configuration Test Failed: {e}\n")
        results.append(("Configuration", False))

    # Test 3: Prompt Manager
    try:
        results.append(("Prompt Manager", test_prompt_manager()))
    except Exception as e:
        print(f"âœ— Prompt Manager Test Failed: {e}\n")
        results.append(("Prompt Manager", False))

    # Test 4: AI Clients
    try:
        results.append(("AI Clients", test_ai_clients()))
    except Exception as e:
        print(f"âœ— AI Clients Test Failed: {e}\n")
        results.append(("AI Clients", False))

    # çµæœã‚µãƒãƒªãƒ¼
    print("=" * 60)
    print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for name, result in results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"{status} - {name}")

    print(f"\nåˆæ ¼: {passed}/{total} ({passed/total*100:.0f}%)")

    if passed == total:
        print("\nğŸ‰ Phase 1-A åŸºç›¤æ•´å‚™: ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã«åˆæ ¼ã—ã¾ã—ãŸï¼")
        return 0
    else:
        print("\nâš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        return 1


if __name__ == "__main__":
    exit(main())
